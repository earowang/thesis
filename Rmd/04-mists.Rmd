# Data representation, visual and analytical techniques for demystifying temporal missing data {#ch:mists}

Missing data provokes an air of mystery, that makes analysis difficult throughout the exploration loop of transformation, visualization, and modeling. How to handle missing values involves decisions with many degrees of freedom, leading to a tedious and unwieldy process. The challenge of missingness is rooted in seeing what is not there. The aim of this work is to clear that mysterious air away from missing data with the focus on temporal contexts from a data-centric perspective. A new sparse representation facilitates the efficient indexing of runs of missings in time, with supporting operations and visual methods. This places missing data in the spotlight, speaking for themselves. When too many missings are scattered across variables and observations over time, missing data polishing strategies are populated and formulated. This equips analysts with tidy tools to iteratively remove missings from rows and columns, while keeping the temporal nature intact. The accompanying software is the R package **mists**.

```{r mists-initial, echo = FALSE, cache = FALSE, include = FALSE}
read_chunk('scripts/mists.R')
read_chunk('scripts/mists-wdi.R')
read_chunk('scripts/mists-pedestrian.R')
```

```{r rle-na-text}
rle_na1 <- function() {
  if (knitr::is_latex_output()) {
    "RLE \\<`NA`\\>"
  } else {
    "RLE \\<NA\\>"
  }
}
```

```{r mists-load}
```

## Introduction {#sec:mists-intro}

Temporal missingness occurs when there is an absence of a value in time. For regularly spaced data, which is often assumed in time series, implicit missing values can be relatively easily spotted because there are gaps in the regularity. These can be converted to explicit missing values with ease. In irregular temporal data, missings should be specified explicitly in the raw data. Once the missings are explicitly declared, the patterns can be explored, and appropriate methods for imputation employed. Missing value research has a long history, but little attention has been paid to temporal missings.

@Little1988test established a taxonomy for missing data mechanisms: missing completely at random (MCAR), missing at random (MAR), and missing not at random (MNAR). This is a view of missingness from the probabilistic perspective, because these mechanisms all specify a generating distribution from which to specify imputation methods. A data-centric approach to missings is described in @MANET, which shows how to explore missing value patterns with interactive graphics. @swayne1998 illustrated how using a shadow matrix could be useful for exploring multivariate missings using interactive graphics. A graphical user interface for exploring missing values in multivariate data using static plots is provided by @cheng_visually_2015. Recently, @Tierney2018naniar developed a collection of tidy tools in the R package `naniar` to facilitate transforming, visualizing, and imputing missing data.

In contrast to multivariate data, temporal data has the time dimension that needs to be explored, to understand the temporal dynamics of missing values. Little work has been conducted in this area. @Gschwandtner2012taxonomy provides a taxonomy of time-oriented data quality problems from single and multiple sources. This work is accompanied by an interactive visual system, TimeCleanser [@gschwandtner_timecleanser_2014], for assessing data qualities for time-oriented missing data, which facilitates cleaning different time formats. Missing values are considered to be a data quality issue as a component of that system. The R package **imputeTS** [@Moritz2017imputets] provides time series imputation methods, such as temporal interpolation and Kalman Smoothing [@kalman], with a few graphical methods for summarizing missing values in time series. None of the existing work fully addresses the problem of handling temporal missing data. There is a need for better data structures, and visualization methods to explore temporal missing data, to better understand the temporal dynamics, and prepare it for imputation and subsequent modeling.

The paper is organized as follows. Section \@ref(sec:mists-categories) outlines four categories of temporal missing patterns. Section \@ref(sec:mists-na-rle) proposes a new type of vector class to encode missing values in time, coupled with visual tools (Section \@ref(sec:mists-vis)). A new suite of polishing techniques, for dealing with missings on large collection of series, are discussed in Section \@ref(sec:mists-polish). Applications illustrating the new techniques are in Section \@ref(sec:mists-data). Section \@ref(sec:mists-conclusion) concludes the paper.

## Categories of temporal missing data {#sec:mists-categories}

Missing values in time can occur in many different patterns. Figure \@ref(fig:tbl-x-line) presents a classical time series, monthly totals of international airline passengers from 1949 to 1960 [@Box:1990:TSA:574978], with simulated gaps of missing values arising from four different patterns:

1. sporadically, where data is missing at random time points, which will be called *Missing at Occasions (MO)*.
2. periodically, for example, missing every Tuesday, which will be called *Missing at Periodic time (MP)*. This could be thought of as structural missing values.
3. functionally, such as more frequent with time, as might happen in a longitudinal study where participants drop out increasingly as time progresses. This will be called *Missing at Functional (MF)*.
4. in runs, for example, in an instrument breakdown, it might take some time period to repair the machine. This will be called *Missing at Runs (MR)*.

```{r miss-types}
```

```{r tbl-x-line, fig.height = 5, fig.cap = "(ref:tbl-x-line-cap)"}
```

(ref:tbl-x-line-cap) Line plots of a series spiked with four different types of temporal missing patterns. It is hard to discern the difference in the patterns from line plots, which motivates development of new graphical methods for exploring temporal missingness.

This categorization may not be exhaustive, although with combinations these four types can form a wide range of temporal missing data patterns.

Some of these types can be mapped to probability nomenclature for missing values. MO mirrors MCAR, where missings are completely at random. MP and MF are forms of MAR, where a known variable could be used to build imputation models. MR does not have an analogy.

It is difficult to detect the missing patterns, or discern the difference, from Figure \@ref(fig:tbl-x-line). This is a typical way to plot time series in the presence of missing values, but it is not a good diagnostic plot. Thus, the motivation for this new work, a desire to provide better diagnostic plots for exploring temporal missings, that neatly integrates with the tidy data workflow. To lubricate this work, a new data structure is developed, and discussed in the next section.

## New data abstraction and operations for missing data in time {#sec:mists-na-rle}

Figure \@ref(fig:tbl-x-line) is a typical time series plot, plotting the present data and leaving gaps between to indicate what is not available. The result is that missing values receive little attention, due to a lack of visual emphasis. A need to better represent and display missing data in time is exposed. To begin this process, it is convenient to first address appropriate computer representation. In R, missing values are encoded as `NA`. However, the notion of an ordered `NA` does not exist. A new abstraction for ordered `NA` provides the scope for conveying the temporal locations and dependencies in missing data.

### New encoding for indexing missing data by time

Inspired by run-length encoding (RLE), a new encoding is proposed to solely extract the `NA`s from time-indexed data and compress them in a simpler form, namely "`r rle_na1()`". It comprises three components to locate the missings and mark their corresponding runs: (1) positions where `NA` starts, (2) run lengths (`NA` in a row), and (3) interval (for example, hourly or yearly intervals). This implies that time indices should be unique.

This new encoding purely focuses on indexed missing values, separated from its data input. It is partially lossless, because its reverse operation can recover the original positions of missing values, but not the whole data. It is most useful and compact on indexing runs of missing data, requiring less storage than its original lengthy form. However, when missings mostly involve runs of length one, it is not that advantageous. Considering the missingness types of *Missing at Occasions* and *Missing at Runs* in Figure \@ref(fig:tbl-x-line), the former occupies 14 positions to store `NA`s; while the latter uses 7 positions for storing more `NA`s than the former as a sparser representation. The `r rle_na1()` is easy to interpret: a sequence of 12 `NA`s beginning at 1949 March, followed by 13 `NA`s since 1950 August, and so on, for the latter.

\newpage

```{r na-rle-ex1, linewidth = 70}
```

The instance of `r rle_na1()` is a reduced form for representing `NA` in time, built on top of the new **vctrs** framework [@R-vctrs].

### Supporting functions operating on `r rle_na1()`

The `r rle_na1()` prioritizes indexed missing data as the raw data itself, that provides the opportunities to manipulate the missings with many useful operations.

It is computationally efficient to sum (`sum()`) and count (`length()`) the run lengths over a standalone `r rle_na1()`, than directly dealing with its original form for identical results. Other mathematical functions, such as `mean()` and `median()`, make it accessible to compute runs-related statistics. For example, `mean()` gives the average of missings *per run*. If not going on the route of RLE, it would be cumbersome to compute these statistics otherwise.

These math operations primarily require a singular `r rle_na1()` at a time. The other set is the set operators that performs set union (`union()`), intersection (`intersect()`), and asymmetric difference (`setdiff()`) on a pair of `r rle_na1()`. They are useful for exploring the association between multiple sets of missing data. For example, the `intersect()` operator could tell if they overlap with each other and by how much, which powers one of the plots in the next section. Since set operators are binary functions, a collection of series can be successively combined and applied to give an overall picture about all.

## Visual methods for exploring temporal missingness {#sec:mists-vis}

The `r rle_na1()` object provides an additional layer that adheres to the original data. To frame this in the grammar of graphics, indexed missing data can be considered as a graphical layer on top of the existing data plot, infusing the missings into a richer data context instead of an isolated context. The **imputeTS** R package makes a gallery of graphics available for plotting the distribution and aggregation of missingness for univariate time series, but they are cumbersome and limited. This section enhances the visual toolkit for temporal missing data.

### Visualizing distributions

The range plot is designed to focus primarily on missingness. Figure \@ref(fig:na-rle-rangeplot) shows the range plots of the four scenarios. A line range with closing points corresponds to a run length in the `r rle_na1()`, and a single point when the element is of length one. The range plot is the graphical equivalent of `r rle_na1()`. The missingness patterns (MO, MP, MF, MR) are clearer in this compact display, than the gaps in the original series (Figure \@ref(fig:tbl-x-line)).

```{r tbl-x-list-of}
```

```{r na-rle-rangeplot, fig.height = 2.5, fig.cap = "(ref:na-rle-rangeplot-cap)"}
```

(ref:na-rle-rangeplot-cap) The range plot gives an exclusive focus on missing data over time, a graphical realization of the `r rle_na1()`. The dot indicates a single missing point, and a line range suggests the missings at runs. It is easier to compare and contrast the locations and run lengths of missings across series.

```{r layer-na-rle, fig.height = 4.5, fig.cap = "(ref:layer-na-rle-cap)"}
```

(ref:layer-na-rle-cap) The jailbird plot puts the focus on the locations and lengths of missing values, which allows for better detection of different patterns. Using gray for the bars, with black lines for the complete values, enables the continuity principle of perception to take effect. Implicitly, the viewer's brain imputes the missings to extend the series through the "occluded" parts.

Figure \@ref(fig:layer-na-rle) focuses on the distribution of missing values as well as the data. It is an adaptation of the plot provided by the **imputeTS** `plotNA.distribution()` function. A new data layer, associated with the pre-computed `r rle_na1()`, is visually presented as strips or rectangles to the existing data plot of Figure \@ref(fig:tbl-x-line), and we have aptly named it a *jailbird* plot. The purpose of the strips is perceptual: they both mark the location of missings and draw attention to these times, but they stimulate the *continuity principle of perception* where our brains mentally fill in the gap with a pseudo-imputed value.

### Visualizing aggregations

Visualizing aggregations summarizes run lengths of missing data, for example the occurrences of distinctive runs and the tallies. The **imputeTS** package implements this idea in the form of bar charts as the `plotNA.gapsize()` function. Figure \@ref(fig:imputets-gapsize) shows this plot, which contrasts the counting of missing values occurring by the two mechanisms, Missing at Occasions and Runs. It takes some time to digest this plot. The number of runs is a as categorical variable, with the left bar mapped to the frequencies and the right mapped to total missings. The confusion arises from Figure \@ref(fig:imputets-gapsize) because occurrences and tallies are separated as colored bars but the count is displayed on the same axis. A better alternative to use a spineplot to represent this information (Figure \@ref(fig:na-rle-spinoplot)). A spine plot is a special case of a mosaic plot [@Hofmann2006]. A 100% bar is mapped to a run length: the width displays the number of occurrences, and the corresponding bar area is naturally the total number of missings, both of which remain treated as quantitative variables.

```{r imputets-gapsize, fig.height = 3, fig.cap = "(ref:imputets-gapsize-cap)"}
```

(ref:imputets-gapsize-cap) The occurrence plot show the summaries of distinct gap sizes, provided by the **imputeTS** package. The left-hand bar gives the number of occurrences for each gap size, with the corresponding tallies of `NA` on the right-hand side.

```{r na-rle-spinoplot, fig.height = 5, fig.cap = "(ref:na-rle-spinoplot-cap)"}
```

(ref:na-rle-spinoplot-cap) The gasp plot turns the focus from distributions to aggregations of run lengths, for the four missing patterns. Missing at Runs is clearly differentiated from the rest.

Figure \@ref(fig:na-rle-spinoplot) demonstrates the use of the gasp plot (also known as the spineplot) for visualizing the aggregations of missingness in time. Since the plot is faceted by the four types, it shows the individual distribution of run lengths and compares between, but puts no emphasis on the association between them. The four types of missing patterns produce quite different gasp plots.

Figure \@ref(fig:na-rle-spinoplot2) explores the idea of how missings intersect on the two variables. The 100% of the bar in Figure \@ref(fig:na-rle-spinoplot) is replaced by the proportion of intersection with another variable. The missing values of the *Occasions* type intersects with the *Runs* type by 25% in the left panel. The right panel is the swap between them, showing that the overlapping missings of the *Runs* type with the *Occasions* occur to the longer runs. This also showcases the use of the set operation `intersect()`.

```{r na-rle-spinoplot2, fig.height = 3, fig.cap = "(ref:na-rle-spinoplot2-cap)"}
```

(ref:na-rle-spinoplot2-cap) The spineplot is extended to temporal missing data for exploring associations based on their run lengths. The purple area highlights their intersections in time. The Runs type overlaps the Occasions in the longer run.

## Scaling up to large collections of temporal data {#sec:mists-polish}

Section \@ref(sec:mists-vis) discussed the graphics for revealing and understanding the missingness patterns in a handful of series. However, they have little capacity for scaling up to handling a large collection of temporal data, which involve many series and many measures in a table. A solution to dealing with missing values at scale is proposed and described in this section, which is referred to "missing data polish". @medpolish coined the term "median polish" --- an iterative procedure to obtain an additive-fit model for data. Here, a new analytical technique is developed to strategically remove observations and variables in order to reduce the proportion of missing values in the data, called "missing data polish". The polishing process can give numerical summaries to facilitate the understanding, and in turn produce a reasonable subset to work with, especially when too many missings are scattered across variables and observations.

### Polishing missing data by variables and observations

The polishing procedure assumes that the incoming data is a "tsibble" [@tsibble]. The tsibble is a modern re-imagining of temporal data, which formally organizes a collection of related observational units and measurements over time in a tabular form. A tsibble consists of index, key, and measured variables in a long format. The index variable contains time in chronological order; the key uniquely defines each observational unit over time; columns other than index and key are classified as measures.

This data structure invokes polishing procedures in two directions (by rows and columns), resulting in four polishers:

* `na_polish_measures()`: A column polisher for removing measured variables.
* `na_polish_key()`: A row polisher for removing a whole chunk of units across measures.
* `na_polish_index()`: A row polisher for removing leading indexed observations within each unit across measures.
* `na_polish_index2()`: A row polisher for removing trailing indexed observations within each unit across measures.

This set of polishers covers the basics of missing values occurring in a tsibble. The decision rule on deleting certain rows or columns is controlled by a constant cutoff value ($0 \le c \le 1$). Each polisher first computes $p_{i} = \text{proportion of overall missings}$, where $i$ is a partition of the data (i.e. each column for `na_polish_measures()` and each chunk of rows for the rest of polishers). If $p_{i} \ge c$, the $i$th column or chunk of rows will be removed; otherwise as is.

However, an ideal choice of $c$ is not clear. Missing data polishing is an upstream module relative to other analytical tasks from data visualization to modeling. These analytics have various degrees of tolerance for missing values. For example, data plots are almost independent of missing data, implying higher tolerance. For such, specifying a higher $c$ removes little data. On the other hand, (time series) models would likely complain the existence of any missings and some would even decline the job, requiring lower tolerance. A lower $c$ is likely to produce a complete dataset for such downstream analyses, but may remove too much data.

### Formulating polishing strategies

The polishers described in the previous section are the elementary tools provided to analysts for brushing missings away. A few iterations using these functions are often required with lots of manual efforts to achieve a desired result. The polished data can be influenced by the ordering of polishers and cutoff choices. The polishing goal, in general, is to maximize the proportion of missings in the removed data slice as well as to minimize the number of observations to be removed. An automated polishing strategy is formulated to refine the procedure with less human involvement, as implemented in `na_polish_auto()`. It essentially takes care of the sequence of polishers and the number of iterations in operation, but leaves the cutoff in the user's hands. This automating process involves a loss metric in a loop to determine the order the polishers and when to stop the iterations. This loss metric is defined as
\begin{equation}
  l_{i} = (1 - p_{i}) \times \frac{r_{i}}{N},
  (\#eq:mists-loss)
\end{equation}
where $p$ is the proportion of missings, $r$ is the number of removed observations for each data slice $i = 1, \dots$, and $N$ is the total observations. Minimizing the loss $l$ guides the polishing procedure:

1. Run four polishers independently to obtain $l_{i}$.
2. Re-run the polishers sequentially according to the $l_{i}$ from high to low, and obtain $l_{I}$ where $I$ is an iteration.
3. Repeat 1 and 2 until $l_{I} \le \tau$, where $\tau$ is a pre-specified tolerance value close to $0$. (Early exit given a higher $\tau$.)

The companion function `na_polish_autotrace()` documents the entire polishing process above, and traces the $p_{i}$, $r_{i}$, and $l_{i}$ along the way. These quantities can provide useful visual summaries about missing data patterns, and an aid to choose the cutoffs in return.

## Application {#sec:mists-data}

### World development indicators

```{r wdi-load}
```

The motivating example for the polishing techniques is the World Development Indicators (WDI), sourced from the @wdi. The dataset presents 55 national estimates of development indicators from 217 countries and regions around the globe every year from 1969 to 2018 (A data dictionary is given in Table \@ref(tab:wdi-data-dict) in Appendix \@ref(data-dictionary)). It contains `r format(NROW(wdi), big.mark = ",")` observations with `r scales::percent(mean(is.na(wdi[-c(1, 2)])))` of missing values in the measurements. Figure \@ref(fig:wdi-vis) gives the overall picture of missingness in the data. Missingness appears as blocks and strips across observations and variables. Such data involving a great amount of missing values can be overwhelming at first glance. This severely inhibits further analyses.

```{r wdi-vis, fig.height = 7, fig.cap = "(ref:wdi-vis-cap)"}
```

(ref:wdi-vis-cap) Missing data heatmap, with black for missing values and gray for present values. Pixels are arranged as the data cells, reflecting the missingness status. The amount of missings varies vastly by variables.

A grid search on the polishing parameters $c$ and $\tau$ is performed on this dataset to study their robustness. After setting $\tau$ to 0 and 0.1 respectively, a sequence of $c$, ranging from 0.4 (worst) to 0.9 (best) by 0.1, are passed to each polisher. This setup gives `r format(NROW(cutoff_grids) * 2, big.mark = ",")` possible combinations for the automatic polishing strategy to take place.

```{r wdi-pass, fig.height = 3, fig.cap = "(ref:wdi-pass-cap)"}
```

(ref:wdi-pass-cap) The loss metrics against the number of iterations conditional on two tolerance values. When $\tau = 0$, it can take the number of iterations up to 21, with marginal improvements from the second iteration onwards.

```{r wdi-grid-plot, fig.cap = "(ref:wdi-grid-plot-cap)"}
```

(ref:wdi-grid-plot-cap) The beeswarm plot showing the effect of the grid parameters for four polishers. The choice of cutoff ($c$) makes a significant impact on `na_polish_key()` and `na_polish_measures()`, but little changes for the polishing indexes (first two columns).

Figure \@ref(fig:wdi-pass) exhibits the number of iterations needed to exit the polishing,with $l \le \tau$ given the same set of $c$ when $\tau = 0$ or $\tau = 0.1$. If $\tau = 0$, the procedure can take up to 21 iterations to complete; but if $\tau = 0.1$, maximum 4 iterations are sufficient. The loss metric dramatically declines from iteration 1 to 2, with a marginal decrease afterwards for both $\tau$. It suggests $\tau = 0.1$ is perhaps a right amount of tolerance and saves a considerable amount of computational time. When $\tau = 0.1$, Figure \@ref(fig:wdi-grid-plot) shows the influence of different values of $c$ on the polishing results. Following the rule of minimizing the loss (i.e. maximizing the proportion of missing values while minimizing the proportion of removed data), the polishers `na_polish_index()`, `na_polish_key()`, and `na_polish_measures()`, suggest that 0.5 is a good candidate of $c$. No matter which value $c$ takes, the `na_polish_index2()` polisher behaves constantly.

```{r wdi-polished-vis, fig.height = 7, fig.cap = "(ref:wdi-polished-vis-cap)"}
```

(ref:wdi-polished-vis-cap) Missingness heatmap for the polished data. The polished data gives 11.8% missing values, compared to 44.9% in Figure \@ref(fig:wdi-vis).

Using $c = 0.5$ for each polisher and $\tau = 0.1$, the automatic polishing process goes through 3 iterations to get the data polished. Removing 11 of 55 variables and 37 of 217 countries, produces a polished data with 11.8% instead of 44.9% missing values. Figure \@ref(fig:wdi-polished-vis) displays the missingness map for the polished data. Comparing to the original dataset, the polished subset shrinks in size, but is much more complete, making it more feasible to impute and do further analysis.

The polishing process prepares the data for imputation, and in turn for modeling. Figure \@ref(fig:mists-pipeline) displays the data pipeline that polishes, filters in and out, imputes, models and forecasts each series. The series for China is used too illustrate the result from this pipeline. In this subset, 14 of 29 variables contain missing data. The jailbird plot (Figure \@ref(fig:wdi-chn-imputed)) is used to highlight the blocks of missings. The red dots represent imputed values, computed using the Stineman interpolation [@stineman; @R-stinepack] for each series. The results look very consistent for each series. The complete data is passed into Exponential Smoothing models (ETS) and forecast for the next three years. Figure \@ref(fig:wdi-chn-ets) shows the point forecasts with 80% and 95% prediction intervals. ETS does not accept any missings, so this pipeline has provided a smooth flow of messy temporal data into tidy model output.

```{r mists-pipeline, fig.cap = "(ref:mists-pipeline-cap)"}
include_graphics("img/mists-pipeline.png")
```

(ref:mists-pipeline-cap) The pipeline demonstrates the sequence of functions required for modeling data with a large amount of missings. It begins with the polishing, and then transform, interpolate, model, and forecast.

```{r wdi-chn}
```

```{r wdi-chn-imputed, fig.height = 9, fig.cap = "(ref:wdi-chn-imputed-cap)"}
```

(ref:wdi-chn-imputed-cap) The jailbird plot, for the subset of 14 time series from China, overlaid with imputed values (red). The gaps are filled with the well-behaved imputations that are consistent with the complete data.

```{r wdi-chn-ets, fig.height = 9, fig.cap = "(ref:wdi-chn-ets-cap)"}
```

(ref:wdi-chn-ets-cap) Three-year forecasts built with ETS models on the polished and imputed data for China, with 80% and 95% prediction intervals.

### Melbourne pedestrian sensors

Many sensors have been installed that track hourly pedestrian tallies in downtown Melbourne [@ped], as part of the emerging smart city plan. It is valuable for understanding the rhythm of daily life of people in the city. There are numerous missing values, likely due to sensors failing for periods of time. Figure \@ref(fig:pedestrian-rangeplot) illustrates the distributions of missingness in 2016 across 43 sensors, using the range plot organized from the most missing sensor to the least.

```{r pedestrian-load}
```

```{r pedestrian-rangeplot, fig.height = 7, fig.cap = "(ref:pedestrian-rangeplot-cap)"}
```

(ref:pedestrian-rangeplot-cap) The range plot arranges the 43 pedestrian sensors from most missing to the least. Missing at Runs and Occasions can be found in the data. Across series, many missings can be seen to be occurring at similar times. The common missing at the beginning of October is likely the start of daylight savings (summer) time in Melbourne, where an hour disappears from the world.

```{r spencer-spinoplot, fig.height = 3, fig.width = 3, out.width = "40%", fig.cap = "(ref:spencer-spinoplot-cap)"}
```

(ref:spencer-spinoplot-cap) The gasp plot for missings at Spencer St-Collins St (South), with six disjoint runs coupled with the frequencies of one to four.

```{r spencer-jailbird, fig.height = 2.5, fig.cap = "(ref:spencer-jailbird-cap)"}
```

(ref:spencer-jailbird-cap) The jailbird with colored imputed data using the seasonal split method for the sensor at Spencer Street from 2016 August to December. Strong seasonal features are prominent in the original data, but it is hard to detect the seasonal pattern from the imputed data.

In contrast to the WDI data, the pedestrian data features multiple seasonal components: time of day, day of week, and different types of days like public holidays. Seasonal patterns corresponding to these temporal elements can be seen. The jailbird plot in Figure \@ref(fig:spencer-jailbird), overlays imputed values (red), computed using the seasonal split method available in the **imputeTS** package. They appear to fall in the reasonable range, but do not seem to have captured the seasonality. Mostly what can be observed in the long time series is work day vs not seasonality. Figure \@ref(fig:spencer-imputes) drills down into the finer daily seasonality. It splits the series into work and non-work days, colored by imputed or not. The imputation actually does well to capture the daily patterns, at least for working days, It fails on non-working days because it estimates a commuter pattern. This imputation method doesn't perform well with the multiple seasonality.

```{r spencer-imputes, fig.height = 4, fig.cap = "(ref:spencer-imputes-cap)"}
```

(ref:spencer-imputes-cap) Examining the daily seasonality, relative to the work day vs not components, using faceted line plots. The imputation (purple) grasps the key moments (morning and afternoon commutes, and lunch break) in a work day, but is unable to build the non-work profile.

## Conclusion {#sec:mists-conclusion}

The presence of missing values provides a barrier to getting analysis started, and if the proportion of missing is high, imputation can be unreliable. Restricting to only complete data might produce an analysis using little data. This paper has presented a new data structure, several new visual techniques, and an algorithm for handling large amounts of temporal missings. These tools facilitate exploring and understanding missing value patterns, and diagnosing the imputations in preparation for time series modeling. These are available in the R package, **mists**.

There are some natural next directions of this work. The literature review uncovered a lack of a comprehensive system for simulating different types of missing value patterns. Conceptualizing and developing a system would greatly help in understanding what is seen in practice. Much of the early work on exploratory methods for missings provided interactive graphical methods. The plots developed in this paper could be adapted and extended to incorporate interaction, as new technology arises that makes this easier.

## Acknowledgements

This article was created with knitr [@knitr] and R Markdown [@rmarkdown]. The **mists** R package is available on Github <https://github.com/earowang/mists>.
